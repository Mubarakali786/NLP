
Open In Colab

import spacy

# Load the English model "en_core_web_sm"
nlp = spacy.load("en_core_web_sm")

# Given sentences
sentences = ["The cat sat on the mat.", "She quickly ran to catch the bus."]

# Perform dependency parsing for each sentence
for sentence in sentences:
    # Process the text using SpaCy
    doc = nlp(sentence)

    # Print the token dependencies
    print("\nOriginal Sentence:", sentence)
    for token in doc:
        print(f"{token.text} --({token.dep_})--> {token.head.text}")

     
Original Sentence: The cat sat on the mat.
The --(det)--> cat
cat --(nsubj)--> sat
sat --(ROOT)--> sat
on --(prep)--> sat
the --(det)--> mat
mat --(pobj)--> on
. --(punct)--> sat

Original Sentence: She quickly ran to catch the bus.
She --(nsubj)--> ran
quickly --(advmod)--> ran
ran --(ROOT)--> ran
to --(aux)--> catch
catch --(advcl)--> ran
the --(det)--> bus
bus --(dobj)--> catch
. --(punct)--> ran
